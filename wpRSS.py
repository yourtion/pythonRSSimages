#!/usr/bin/env python# -*- coding: UTF-8 -*-import sysreload(sys)sys.setdefaultencoding("utf-8")import feedparserfrom bs4 import BeautifulSoupimport urllib2from os.path import basenamefrom urlparse import urlsplitimport ostry:	feed_ = feedparser.parse("")	count = len(feed_['entries'])	counts = [i for i in range(count)]	y = 0	for y in range(len(feed_.entries)):		title =  feed_.entries[y].title		author = feed_.entries[y].author		save_path = 'imgs/' + author + "/" + title		if not os.path.exists(save_path):			os.makedirs(save_path)		cont = feed_.entries[y].content[0].value		imc = BeautifulSoup(cont)		i=0		for i in range(len(imc.find_all('img'))):			img_src = imc.find_all('img')[i]['src']			try:				imgData = urllib2.urlopen(img_src).read()				fileName = save_path + '/' + basename(urlsplit(img_src)[2])				if os.path.exists(fileName):					continue				output = open(fileName,'wb')				output.write(imgData)				output.close()				print "Finished download", img_src			except:				print "Download %s failed" %img_srcexcept:	print 'RSS error ÔºÅ'	exit()